{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nprint(\"Hello World\")\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-27T02:14:13.170747Z","iopub.execute_input":"2024-05-27T02:14:13.171131Z","iopub.status.idle":"2024-05-27T02:14:13.178122Z","shell.execute_reply.started":"2024-05-27T02:14:13.171098Z","shell.execute_reply":"2024-05-27T02:14:13.177116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport PIL as image_lib\nimport tensorflow as tf\nimport pathlib\nfrom datasets import load_dataset\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:53.564905Z","iopub.execute_input":"2024-05-27T22:15:53.565855Z","iopub.status.idle":"2024-05-27T22:15:53.571036Z","shell.execute_reply.started":"2024-05-27T22:15:53.565819Z","shell.execute_reply":"2024-05-27T22:15:53.570092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import dataset","metadata":{}},{"cell_type":"code","source":"# dataset = load_dataset('alkzar90/NIH-Chest-X-ray-dataset', 'image-classification', trust_remote_code=True)\nds = load_dataset(\"keremberke/chest-xray-classification\", name=\"full\")\nexample = ds['train'][0]","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:55.183162Z","iopub.execute_input":"2024-05-27T22:15:55.183851Z","iopub.status.idle":"2024-05-27T22:15:57.485854Z","shell.execute_reply.started":"2024-05-27T22:15:55.183820Z","shell.execute_reply":"2024-05-27T22:15:57.485091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(ds)\nprint(example)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:16:04.233399Z","iopub.execute_input":"2024-05-27T22:16:04.233781Z","iopub.status.idle":"2024-05-27T22:16:04.238952Z","shell.execute_reply.started":"2024-05-27T22:16:04.233752Z","shell.execute_reply":"2024-05-27T22:16:04.237971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = ds['train']\nvalidation_dataset = ds['validation']\ntest_dataset = ds[\"test\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:16:13.156128Z","iopub.execute_input":"2024-05-27T22:16:13.156491Z","iopub.status.idle":"2024-05-27T22:16:13.161139Z","shell.execute_reply.started":"2024-05-27T22:16:13.156464Z","shell.execute_reply":"2024-05-27T22:16:13.160105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_dataset)\nprint(type(train_dataset))\nprint(train_dataset.features)\nprint(\"Size in bytes:\", train_dataset.dataset_size)\nprint()\nprint(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:16:15.657104Z","iopub.execute_input":"2024-05-27T22:16:15.657473Z","iopub.status.idle":"2024-05-27T22:16:15.663452Z","shell.execute_reply.started":"2024-05-27T22:16:15.657443Z","shell.execute_reply":"2024-05-27T22:16:15.662479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_height = 240\nimg_width = 240\nbatch_size = 32\nnum_classes = 2  # Adjust this based on your dataset\n\n'''\nFunction to preprocess the images themselves by:\n1) Turning them into numpy arrays\n2) Resizing the images down to 240x240 pixels\n3) using the specific resnet preprocess_input function on the final image\n'''\ndef preprocess_function(example):\n    # Access the in-memory image data\n    image = example['image']\n    \n    # Convert the image to a tensor\n    image = tf.convert_to_tensor(np.array(image))\n    \n    # Resize the image\n    image = tf.image.resize(image, [img_height, img_width])\n    \n    # Preprocess the image for ResNet50\n    image = tf.keras.applications.resnet50.preprocess_input(image)\n    \n    # Convert label to categorical\n    label = to_categorical(example['labels'], num_classes=num_classes)\n    \n    return (image, label)\n\n'''\nConverts data set into specifically a tensor flow batched dataset\nwhich is required to train a model using the tensor flow API\n'''\ndef to_tf_dataset(dataset, batch_size):\n    tf_dataset = tf.data.Dataset.from_generator(\n        lambda: (preprocess_function(example) for example in dataset),\n        output_signature=(\n            tf.TensorSpec(shape=(img_height, img_width, 3), dtype=tf.float32),\n            tf.TensorSpec(shape=(num_classes,), dtype=tf.float32)\n        )\n    )\n    return tf_dataset.shuffle(buffer_size=len(dataset)).batch(batch_size).repeat()\n\ntrain_tf_dataset = to_tf_dataset(train_dataset, batch_size)\nvalidation_tf_dataset = to_tf_dataset(validation_dataset, batch_size)\ntest_tf_dataset = to_tf_dataset(test_dataset, batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:16:18.747499Z","iopub.execute_input":"2024-05-27T22:16:18.748305Z","iopub.status.idle":"2024-05-27T22:16:18.836704Z","shell.execute_reply.started":"2024-05-27T22:16:18.748271Z","shell.execute_reply":"2024-05-27T22:16:18.835782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(train_tf_dataset))\n# prev: <_BatchDataset element_spec=(TensorSpec(shape=(None, 240, 240, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>\n# curr: <_BatchDataset element_spec=(TensorSpec(shape=(None, 240, 240, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:16:21.084253Z","iopub.execute_input":"2024-05-27T22:16:21.084611Z","iopub.status.idle":"2024-05-27T22:16:21.089746Z","shell.execute_reply.started":"2024-05-27T22:16:21.084583Z","shell.execute_reply":"2024-05-27T22:16:21.088879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_tf_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T21:00:37.474132Z","iopub.execute_input":"2024-05-27T21:00:37.474748Z","iopub.status.idle":"2024-05-27T21:00:37.479386Z","shell.execute_reply.started":"2024-05-27T21:00:37.474716Z","shell.execute_reply":"2024-05-27T21:00:37.478470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\npretrained_model = tf.keras.applications.ResNet50(\n    include_top=False, # Allow adding input and outputs for custom problem\n    input_shape=(img_height,img_width,3), # This is the shape of our images (not sure what the 3 is though)\n    pooling=\"avg\",\n    classes=2,\n    weights=\"imagenet\"\n)\n\nfor layer in pretrained_model.layers:\n    layer.trainable=False\n\nmodel.add(pretrained_model)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:26:59.184280Z","iopub.execute_input":"2024-05-27T22:26:59.184877Z","iopub.status.idle":"2024-05-27T22:27:00.295695Z","shell.execute_reply.started":"2024-05-27T22:26:59.184843Z","shell.execute_reply":"2024-05-27T22:27:00.294681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.add(Flatten()) # Transforms input layer into 1-D array, allows resent output to be feed to our fully connect FFNN that gets added next\nmodel.add(Dense(512, activation='relu')) # Fully connected layer of 512 likely because ResNet returns a 512 size vector\nmodel.add(Dense(2, activation=\"softmax\")) # Adds a final output layer with 5 nodes for each class and softmax to get a final classifier","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:27:00.903871Z","iopub.execute_input":"2024-05-27T22:27:00.904236Z","iopub.status.idle":"2024-05-27T22:27:00.911939Z","shell.execute_reply.started":"2024-05-27T22:27:00.904207Z","shell.execute_reply":"2024-05-27T22:27:00.910998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps_per_epoch = len(train_dataset) // batch_size\nvalidation_steps = len(validation_dataset) // batch_size\n\noptimizer=Adam() # learning rate is 0.001\nloss_function = \"categorical_crossentropy\"\nmetrics=[\"accuracy\"]\nmodel.compile(optimizer=optimizer, loss=loss_function, metrics=metrics) # configures model for training\nepochs = 5\nhistory = model.fit(train_tf_dataset, validation_data=validation_tf_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps) # train the model for a fixed number of epochs","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:27:02.975137Z","iopub.execute_input":"2024-05-27T22:27:02.975797Z","iopub.status.idle":"2024-05-27T22:31:08.483845Z","shell.execute_reply.started":"2024-05-27T22:27:02.975761Z","shell.execute_reply":"2024-05-27T22:31:08.482525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8)) # Set our graph sizes to 8x8 for latter\nepoch_range = range(epochs)\nplt.plot(epoch_range, history.history['accuracy'], label=\"Training Accuracy\")\nplt.plot(epoch_range, history.history['val_accuracy'], label=\"Validation Accuracy\")\nplt.axis(ymin=0.4,ymax=1)\nplt.grid()\nplt.title('Large Fully Trained Model Accuracy using 5 epochs')\n\nplt.ylabel('Accuracy')\n\nplt.xlabel('Epochs')\n\nplt.legend(['train', 'validation'])","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:31:32.537673Z","iopub.execute_input":"2024-05-27T22:31:32.538350Z","iopub.status.idle":"2024-05-27T22:31:32.897826Z","shell.execute_reply.started":"2024-05-27T22:31:32.538319Z","shell.execute_reply":"2024-05-27T22:31:32.896973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(history.history[\"val_accuracy\"][-1]) # Prints the final accuray of our model on the dev set","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:21:50.832203Z","iopub.execute_input":"2024-05-27T22:21:50.832546Z","iopub.status.idle":"2024-05-27T22:21:50.837660Z","shell.execute_reply.started":"2024-05-27T22:21:50.832520Z","shell.execute_reply":"2024-05-27T22:21:50.836847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test accuracy on the seperate test set now","metadata":{}},{"cell_type":"code","source":"steps = len(test_dataset) // 32\ntest_loss, test_accuracy = model.evaluate(test_tf_dataset, steps=steps)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:32:03.607542Z","iopub.execute_input":"2024-05-27T22:32:03.607930Z","iopub.status.idle":"2024-05-27T22:32:08.754115Z","shell.execute_reply.started":"2024-05-27T22:32:03.607894Z","shell.execute_reply":"2024-05-27T22:32:08.753288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_accuracy)\nbigModelTestAccuracy = test_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:32:10.435132Z","iopub.execute_input":"2024-05-27T22:32:10.435496Z","iopub.status.idle":"2024-05-27T22:32:10.440370Z","shell.execute_reply.started":"2024-05-27T22:32:10.435468Z","shell.execute_reply":"2024-05-27T22:32:10.439469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Show images with labels and predictions","metadata":{}},{"cell_type":"code","source":"class_names = [\"normal\", \"pnemonia\"]\nplt.figure(figsize=(10,10)) # Set the size of the images we are generating\nfor images, labels in test_tf_dataset.take(1):\n    predictions = model.predict(images)\n    for var in range(6):\n        # modelPrediction = demo_resnet_model.predict(images[var])\n        classIdx = np.argmax(labels[var].numpy()) # Get the class number for the predicted flower. Use argmax because of the final layer using softmax\n        className = class_names[classIdx]\n        predictedClassName = class_names[(np.argmax(predictions[var]))]\n        ax = plt.subplot(3, 3, var + 1)\n        plt.imshow(images[var].numpy().astype(\"uint8\"))\n        plt.text(x=0, y=1.05, s=f\"Predicted: {predictedClassName}\")\n        plt.title(label=className)\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:22:15.397000Z","iopub.execute_input":"2024-05-27T22:22:15.397624Z","iopub.status.idle":"2024-05-27T22:22:24.171340Z","shell.execute_reply.started":"2024-05-27T22:22:15.397590Z","shell.execute_reply":"2024-05-27T22:22:24.170388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"/kaggle/working/ResNet50_smallDataset.keras\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # This breaks right now because of something with the Flatten() call being wrong\n# loaded_model = load_model(\"/kaggle/working/ResNet50_smallDataset.keras\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now try to train the model using only a subset of the training data","metadata":{}},{"cell_type":"code","source":"import random\n\n# Assuming train_dataset is your original dataset\nnum_rows = 32 # Similar size as few shot set\n\n# Set a random seed for reproducibility\nrandom.seed(12)\n\n# Select 1000 random indices from the original dataset\nindices = random.sample(range(len(train_dataset)), num_rows)\n\n# Use the select method to create a new dataset with the selected indices\nsubset_dataset = train_dataset.select(indices)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:32:17.973203Z","iopub.execute_input":"2024-05-27T22:32:17.973875Z","iopub.status.idle":"2024-05-27T22:32:17.983775Z","shell.execute_reply.started":"2024-05-27T22:32:17.973840Z","shell.execute_reply":"2024-05-27T22:32:17.982917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Turn the dataset into a tensorflow compatitable object and resize images","metadata":{}},{"cell_type":"code","source":"subset_tf_dataset = to_tf_dataset(subset_dataset, batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:32:20.944057Z","iopub.execute_input":"2024-05-27T22:32:20.944432Z","iopub.status.idle":"2024-05-27T22:32:20.979285Z","shell.execute_reply.started":"2024-05-27T22:32:20.944402Z","shell.execute_reply":"2024-05-27T22:32:20.978477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_height, img_width = 240, 240\nmodel2 = Sequential()\npretrained_model = tf.keras.applications.ResNet50(\n    include_top=False, # Allow adding input and outputs for custom problem\n    input_shape=(img_height,img_width,3), # This is the shape of our images (not sure what the 3 is though)\n    pooling=\"avg\",\n    classes=2,\n    weights=\"imagenet\"\n)\n\nfor layer in pretrained_model.layers:\n    layer.trainable=False\n\nmodel2.add(pretrained_model)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:32:22.316861Z","iopub.execute_input":"2024-05-27T22:32:22.317582Z","iopub.status.idle":"2024-05-27T22:32:24.031852Z","shell.execute_reply.started":"2024-05-27T22:32:22.317552Z","shell.execute_reply":"2024-05-27T22:32:24.030843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.add(Flatten()) # Transforms input layer into 1-D array, allows resent output to be feed to our fully connect FFNN that gets added next\nmodel2.add(Dense(512, activation='relu')) # Fully connected layer of 512 likely because ResNet returns a 512 size vector\n# model2.add(Dense(512, activation='leaky_relu'))\nmodel2.add(Dense(2, activation=\"softmax\")) # Adds a final output layer with 5 nodes for each class and softmax to get a final classifier","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:32:28.009760Z","iopub.execute_input":"2024-05-27T22:32:28.010125Z","iopub.status.idle":"2024-05-27T22:32:28.019618Z","shell.execute_reply.started":"2024-05-27T22:32:28.010097Z","shell.execute_reply":"2024-05-27T22:32:28.018692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps_per_epoch = len(subset_dataset) // batch_size\nvalidation_steps = len(validation_dataset) // batch_size\noptimizer=Adam() # learning rate is 0.001\nloss_function = \"categorical_crossentropy\"\nmetrics=[\"accuracy\"]\nmodel2.compile(optimizer=optimizer, loss=loss_function, metrics=metrics) # configures model for training\nepochs = 5\nhistory2 = model2.fit(subset_tf_dataset, validation_data=validation_tf_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps) # train the model for a fixed number of epochs","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:32:29.595725Z","iopub.execute_input":"2024-05-27T22:32:29.596602Z","iopub.status.idle":"2024-05-27T22:33:35.645783Z","shell.execute_reply.started":"2024-05-27T22:32:29.596571Z","shell.execute_reply":"2024-05-27T22:33:35.644948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8)) # Set our graph sizes to 8x8 for latter\nepoch_range = range(epochs)\nplt.plot(epoch_range, history2.history['accuracy'], label=\"Training Accuracy\")\nplt.plot(epoch_range, history2.history['val_accuracy'], label=\"Validation Accuracy\")\nplt.axis(ymin=0.4,ymax=1)\nplt.grid()\nplt.title('Naievely Trained Model Accuracy with 5 epochs')\n\nplt.ylabel('Accuracy')\n\nplt.xlabel('Epochs')\n\nplt.legend(['train', 'validation'])","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:33:37.687891Z","iopub.execute_input":"2024-05-27T22:33:37.688263Z","iopub.status.idle":"2024-05-27T22:33:37.994061Z","shell.execute_reply.started":"2024-05-27T22:33:37.688234Z","shell.execute_reply":"2024-05-27T22:33:37.993118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps = len(test_dataset) // 32\ntest_loss, test_accuracy = model2.evaluate(test_tf_dataset, steps=steps)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:34:41.547363Z","iopub.execute_input":"2024-05-27T22:34:41.547764Z","iopub.status.idle":"2024-05-27T22:34:46.953729Z","shell.execute_reply.started":"2024-05-27T22:34:41.547732Z","shell.execute_reply":"2024-05-27T22:34:46.952922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_accuracy)\nnaieveSubsetTestAccuracy = test_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:34:46.955264Z","iopub.execute_input":"2024-05-27T22:34:46.955541Z","iopub.status.idle":"2024-05-27T22:34:46.960140Z","shell.execute_reply.started":"2024-05-27T22:34:46.955516Z","shell.execute_reply":"2024-05-27T22:34:46.959220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model with smaller subset of training data gets ~94% accuracy","metadata":{}},{"cell_type":"markdown","source":"### Changes needed for the large multi labeled multi class dataset","metadata":{}},{"cell_type":"code","source":"# model.add(pretrained_model)\n# model.add(Flatten())\n# model.add(Dense(512, activation='relu'))\n# model.add(Dense(15, activation=\"sigmoid\"))\n\n# optimizer = Adam()\n# loss_function = \"binary_crossentropy\"\n# metrics = [\"accuracy\"]\n# model.compile(optimizer=optimizer, loss=loss_function, metrics=metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Try to do sample choosing policy on small data set","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Input\nfrom tensorflow.keras.applications import ResNet50\nimport numpy as np\n\n# Feature extractor using pretrained ResNet50\ndef create_feature_extractor(input_shape):\n    base_model = ResNet50(\n        include_top=False,\n        input_shape=input_shape,\n        pooling=\"avg\",\n        weights=\"imagenet\"\n    )\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    inputs = Input(shape=input_shape)\n    x = base_model(inputs)\n    outputs = Dense(2, activation='softmax')(x)\n    # outputs = Dense(256, activation='relu')(x)  # Adding a trainable layer\n    return Model(inputs, outputs)\n\n# Create feature extractor model\nfew_shot_model = create_feature_extractor((240, 240, 3))\n\n# Function to compute class prototypes\ndef compute_prototypes(support_set_features, support_set_labels, num_classes):\n    prototypes = []\n    for cls in range(num_classes):\n        cls_features = support_set_features[support_set_labels == cls]\n        cls_prototype = tf.reduce_mean(cls_features, axis=0)\n        prototypes.append(cls_prototype)\n    return tf.stack(prototypes)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:01:23.406986Z","iopub.execute_input":"2024-05-27T23:01:23.407699Z","iopub.status.idle":"2024-05-27T23:01:24.501110Z","shell.execute_reply.started":"2024-05-27T23:01:23.407668Z","shell.execute_reply":"2024-05-27T23:01:24.500088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n# Assuming your dataset is already defined and named 'train_tf_dataset'\n# Dataset example structure: <_RepeatDataset element_spec=(TensorSpec(shape=(None, 240, 240, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>\n\ndef split_support_query(dataset, support_size, query_size):\n    support_set_images = []\n    support_set_labels = []\n    query_set_images = []\n    query_set_labels = []\n    \n    for images, labels in dataset.take(1):  # Take the first batch for simplicity\n        # Flatten the batch dimension\n        images = tf.reshape(images, [-1, 240, 240, 3])\n        labels = tf.reshape(labels, [-1, 2])\n        \n        # Support set\n        support_set_images.append(images[:support_size])\n        support_set_labels.append(labels[:support_size])\n        \n        # Query set\n        query_set_images.append(images[support_size:support_size + query_size])\n        query_set_labels.append(labels[support_size:support_size + query_size])\n        \n    support_set_images = tf.concat(support_set_images, axis=0)\n    support_set_labels = tf.concat(support_set_labels, axis=0)\n    query_set_images = tf.concat(query_set_images, axis=0)\n    query_set_labels = tf.concat(query_set_labels, axis=0)\n    \n    return (support_set_images, support_set_labels), (query_set_images, query_set_labels)\n\n# Define the number of examples\nsupport_size = 22  # Number of examples per class for the support set\nquery_size = 10     # Number of examples per class for the query set\n\n# Split the dataset into support and query sets\n(support_set_images, support_set_labels), (query_set_images, query_set_labels) = split_support_query(train_tf_dataset, support_size, query_size)\n\n# Convert labels from one-hot to class indices\n# TODO: Look into using softmax here\nsupport_set_labels = tf.argmax(support_set_labels, axis=1)\nquery_set_labels = tf.argmax(query_set_labels, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:49:47.582657Z","iopub.execute_input":"2024-05-27T22:49:47.582988Z","iopub.status.idle":"2024-05-27T22:50:18.518683Z","shell.execute_reply.started":"2024-05-27T22:49:47.582964Z","shell.execute_reply":"2024-05-27T22:50:18.517645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(query_set_labels))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T21:45:48.125527Z","iopub.execute_input":"2024-05-27T21:45:48.125886Z","iopub.status.idle":"2024-05-27T21:45:48.130994Z","shell.execute_reply.started":"2024-05-27T21:45:48.125862Z","shell.execute_reply":"2024-05-27T21:45:48.130106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loss function for few-shot learning\ndef prototype_loss(prototypes, query_features, query_labels, num_classes):\n    distances = tf.norm(tf.expand_dims(query_features, 1) - tf.expand_dims(prototypes, 0), axis=2)\n    logits = -distances\n    return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=query_labels, logits=logits))\n\n# Training step\ndef train_step(feature_extractor, support_set_images, support_set_labels, query_set_images, query_set_labels, optimizer):\n    with tf.GradientTape() as tape:\n        support_set_features = feature_extractor(support_set_images, training=True)\n        query_set_features = feature_extractor(query_set_images, training=True)\n        \n        prototypes = compute_prototypes(support_set_features, support_set_labels, num_classes=2)\n        loss = prototype_loss(prototypes, query_set_features, query_set_labels, num_classes=2)\n    \n    gradients = tape.gradient(loss, feature_extractor.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, feature_extractor.trainable_variables))\n    return loss\n\n# Training loop\noptimizer = tf.keras.optimizers.Adam()\n\nfor epoch in range(30):  # Number of epochs\n    loss = train_step(\n        few_shot_model, \n        support_set_images, \n        support_set_labels, \n        query_set_images, \n        query_set_labels, \n        optimizer\n    )\n    print(f\"Epoch {epoch+1}, Loss: {loss.numpy()}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:01:29.643016Z","iopub.execute_input":"2024-05-27T23:01:29.643887Z","iopub.status.idle":"2024-05-27T23:01:52.030081Z","shell.execute_reply.started":"2024-05-27T23:01:29.643856Z","shell.execute_reply":"2024-05-27T23:01:52.029128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the validation dataset\nsteps = len(test_dataset) // batch_size\nfew_shot_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nval_loss, val_accuracy = few_shot_model.evaluate(test_tf_dataset, steps=steps)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:01:54.706647Z","iopub.execute_input":"2024-05-27T23:01:54.706994Z","iopub.status.idle":"2024-05-27T23:02:04.566008Z","shell.execute_reply.started":"2024-05-27T23:01:54.706966Z","shell.execute_reply":"2024-05-27T23:02:04.565256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize=(8,8)) # Set our graph sizes to 8x8 for latter\n# epoch_range = range(epochs)\n# plt.plot(epoch_range, history.history['accuracy'], label=\"Training Accuracy\")\n# plt.plot(epoch_range, history.history['val_accuracy'], label=\"Validation Accuracy\")\n# plt.axis(ymin=0.4,ymax=1)\n# plt.grid()\n# plt.title('Model Accuracy')\n\n# plt.ylabel('Accuracy')\n\n# plt.xlabel('Epochs')\n\n# plt.legend(['train', 'validation'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")\nfewShotTestAccuracy = val_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:02:07.454592Z","iopub.execute_input":"2024-05-27T23:02:07.455686Z","iopub.status.idle":"2024-05-27T23:02:07.461037Z","shell.execute_reply.started":"2024-05-27T23:02:07.455618Z","shell.execute_reply":"2024-05-27T23:02:07.460029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Data for the bar chart\nmodels = ['Big Model', 'Naive Subset', 'Few-Shot']\naccuracies = [bigModelTestAccuracy * 100, naieveSubsetTestAccuracy * 100, fewShotTestAccuracy * 100]\n\n# Create the bar chart\nplt.figure(figsize=(8, 6))\nbars = plt.bar(models, accuracies, color=['blue', 'green', 'red'])\n\n# Add title and labels\nplt.title('Model Test Accuracies')\nplt.xlabel('Model Type')\nplt.ylabel('Accuracy (%)')\n\n# Add accuracy values on top of each bar\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, yval + 1, f'{yval}%', ha='center', va='bottom')\n\n# Display the plot\nplt.ylim(0, 100)  # Ensure y-axis starts from 0 to 100 to match the percentage range\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:51:09.521106Z","iopub.execute_input":"2024-05-27T22:51:09.521461Z","iopub.status.idle":"2024-05-27T22:51:09.758932Z","shell.execute_reply.started":"2024-05-27T22:51:09.521432Z","shell.execute_reply":"2024-05-27T22:51:09.758014Z"},"trusted":true},"execution_count":null,"outputs":[]}]}